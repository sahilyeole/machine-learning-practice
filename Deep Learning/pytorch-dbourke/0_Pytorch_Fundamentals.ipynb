{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(torch.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro to Tensors\n",
    "### Creating tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2)\n",
      "2\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "scalar = torch.tensor(2) # torch.tensor() is used to create a tensor\n",
    "print(scalar) # print the tensor\n",
    "print(scalar.item()) # item() is used to get the value of the tensor\n",
    "print(scalar.ndim) # ndim is used to check the dimension of the tensor, like row or column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5])\n",
      "1\n",
      "torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "vector = torch.tensor([1,2,3,4,5])\n",
    "print(vector)\n",
    "print(vector.ndim) # can say no of square brackets (levels of hierarchy)\n",
    "print(vector.shape) # shape is used to check the shape of the tensor i.e. no of items inside square brackets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "2\n",
      "torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "MATRIX = torch.tensor([[1,2,3],[4,5,6],[7,8,9]])\n",
    "print(MATRIX)\n",
    "print(MATRIX.ndim)\n",
    "print(MATRIX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2, 3],\n",
      "         [4, 5, 6],\n",
      "         [7, 8, 9]],\n",
      "\n",
      "        [[1, 2, 3],\n",
      "         [4, 5, 6],\n",
      "         [7, 8, 9]]])\n",
      "3\n",
      "torch.Size([2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "TENSOR = torch.tensor([[[1,2,3],[4,5,6],[7,8,9]],[[1,2,3],[4,5,6],[7,8,9]]])\n",
    "print(TENSOR)\n",
    "print(TENSOR.ndim)\n",
    "print(TENSOR.shape) # 2,3,3 means 2 matrices of 3 rows and 3 columns (3x3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by convention tensors and matrices are represented by capital letters and scalar and vectors by lower case letters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3303, 0.0156, 0.3757, 0.7011],\n",
       "        [0.8701, 0.0452, 0.9146, 0.2333],\n",
       "        [0.1509, 0.6396, 0.4679, 0.4092]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a random tensor\n",
    "random_tensor = torch.rand(3,4) # 3 rows and 4 columns\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#random image tensor\n",
    "random_image_tensor = torch.rand(3,224,244) # height, width, color channel (RGB)\n",
    "random_image_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#zeros and ones tensor\n",
    "zeros_tensor = torch.zeros(3,4)\n",
    "#zeros_tensor = torch.zeros(size=(3,4)) # same way for size\n",
    "zeros_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones_tensor = torch.ones(3,4)\n",
    "ones_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones_tensor.dtype # data type of the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 4, 6, 8])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_to_ten = torch.arange(0,10)\n",
    "torch.arange(start=0,end=10,step=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensors like\n",
    "# to create a tensor with same shape as other tensor\n",
    "ones_tensor_like = torch.zeros_like(ones_tensor)\n",
    "ones_tensor_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.], device='mps:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#default tensor type is float32\n",
    "\n",
    "float_16_tensor = torch.tensor([1,2,3],\n",
    "                                                dtype=torch.float16, # data type of the tensor\n",
    "                                                device='mps', # what device to use, mps for mac metal gpu, by default cpu\n",
    "                                                requires_grad = False # to calculate gradient or not\n",
    ")\n",
    "float_16_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.], device='mps:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor= float_16_tensor.type(torch.float32)\n",
    "float_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 4., 9.], device='mps:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor * float_16_tensor # possible, results in float32 tensor, this is type casting, float * int = float is also possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float16\n",
      "mps:0\n",
      "False\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "print(float_16_tensor.dtype)\n",
    "print(float_16_tensor.device)\n",
    "print(float_16_tensor.requires_grad)\n",
    "print(float_16_tensor.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations on tensors\n",
    "- Addition\n",
    "- Subtraction\n",
    "- Division\n",
    "- Element wise multiplication\n",
    "- Matrix Multiplication (also known as dot product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "operations = torch.tensor([1,2,3])\n",
    "operations +10 # add 10 to each element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "operations * 10 # multiply 10 to each element (element wise multiplication)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mul(operations,10) # same as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1000, 0.2000, 0.3000])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "operations / 10 # divide 10 to each element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "element wise multiplication: tensor([ 4, 10, 18])\n"
     ]
    }
   ],
   "source": [
    "tensor_mul_1 = torch.tensor([1,2,3])\n",
    "tensor_mul_2 = torch.tensor([4,5,6])\n",
    "print(f\"element wise multiplication: {tensor_mul_1 * tensor_mul_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_mul_1 @ tensor_mul_2 # same as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(tensor_mul_1,tensor_mul_2) # same as above"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## some benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1594, 0.9236, 0.7792,  ..., 0.9400, 0.6585, 0.0726]) torch.Size([100000]) 1\n",
      "tensor(33256.2500)\n",
      "CPU times: user 236 ms, sys: 2.27 ms, total: 238 ms\n",
      "Wall time: 237 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "value =0\n",
    "tensor1 = torch.rand(100000)\n",
    "\n",
    "for i in range(len(tensor1)):\n",
    "    value += tensor1[i] * tensor1[i]\n",
    "\n",
    "print(tensor1,tensor1.shape,tensor1.ndim)\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 552 µs, sys: 884 µs, total: 1.44 ms\n",
      "Wall time: 3.03 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(33256.6836)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "torch.matmul(tensor1,tensor1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 118 µs, sys: 30 µs, total: 148 µs\n",
      "Wall time: 130 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(33256.6836)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "tensor1.dot(tensor1) # faster than above\n",
    "# dot and matmul gives same result for 1D tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 100, 100]), 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor2 = torch.rand(100,100,100)\n",
    "tensor2.shape,tensor2.ndim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[25.6859, 22.5577, 24.5622,  ..., 23.8194, 26.1013, 29.0120],\n",
       "         [23.6808, 19.7852, 23.4228,  ..., 21.9910, 23.5933, 25.4758],\n",
       "         [27.0453, 24.8169, 26.9902,  ..., 27.2657, 27.5382, 30.4926],\n",
       "         ...,\n",
       "         [24.2716, 21.5646, 26.4907,  ..., 23.3432, 24.1977, 24.3833],\n",
       "         [24.7912, 22.6355, 26.1069,  ..., 25.5642, 26.7590, 27.0885],\n",
       "         [24.5461, 22.6192, 25.4534,  ..., 24.9676, 26.7283, 27.5899]],\n",
       "\n",
       "        [[26.5610, 25.4498, 24.0886,  ..., 22.3584, 22.4774, 25.3629],\n",
       "         [24.6214, 23.4366, 21.8434,  ..., 20.1613, 23.2423, 23.6459],\n",
       "         [24.9198, 23.7422, 22.8828,  ..., 21.7242, 21.3881, 21.8676],\n",
       "         ...,\n",
       "         [26.4948, 25.5872, 25.4883,  ..., 21.3440, 24.1105, 24.7633],\n",
       "         [27.7279, 26.1621, 25.0435,  ..., 23.8808, 25.4300, 27.8664],\n",
       "         [26.6840, 26.3687, 24.2728,  ..., 23.6758, 24.3738, 25.9267]],\n",
       "\n",
       "        [[23.2790, 22.7735, 21.7494,  ..., 22.5036, 23.7909, 20.2634],\n",
       "         [27.3749, 26.8387, 25.5875,  ..., 24.3961, 27.5135, 23.3722],\n",
       "         [29.3850, 27.8992, 26.8244,  ..., 26.8874, 29.4962, 25.7360],\n",
       "         ...,\n",
       "         [25.0461, 24.6920, 22.3923,  ..., 22.6845, 26.0583, 21.4207],\n",
       "         [28.8451, 26.0969, 27.3208,  ..., 26.8640, 29.0223, 24.0196],\n",
       "         [30.4980, 30.3071, 30.6787,  ..., 28.8893, 31.5277, 28.9890]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[24.9954, 24.6819, 26.8788,  ..., 25.5962, 20.6061, 22.0097],\n",
       "         [24.8848, 23.9818, 28.3201,  ..., 25.9976, 20.7198, 22.7088],\n",
       "         [23.4824, 22.1797, 27.2847,  ..., 25.9382, 20.3184, 22.8015],\n",
       "         ...,\n",
       "         [24.8129, 21.8855, 23.9856,  ..., 24.7837, 18.4604, 21.3505],\n",
       "         [21.7860, 21.4638, 21.2539,  ..., 23.5705, 18.0261, 20.7909],\n",
       "         [24.1543, 23.9583, 27.5768,  ..., 26.3295, 19.5399, 22.1723]],\n",
       "\n",
       "        [[25.0467, 23.4727, 25.9410,  ..., 23.9135, 25.2268, 25.4733],\n",
       "         [22.9533, 23.4898, 23.7214,  ..., 23.1250, 21.3150, 23.4471],\n",
       "         [21.6686, 22.7375, 23.6792,  ..., 20.8500, 20.9554, 23.1510],\n",
       "         ...,\n",
       "         [27.0745, 27.3182, 28.6769,  ..., 27.6828, 26.8016, 28.4994],\n",
       "         [27.5254, 27.1694, 30.9574,  ..., 25.7352, 27.7709, 28.1880],\n",
       "         [26.5714, 26.4686, 27.7096,  ..., 25.3751, 26.3509, 26.4774]],\n",
       "\n",
       "        [[27.5881, 25.1497, 25.4456,  ..., 27.1713, 25.2813, 27.3318],\n",
       "         [28.9517, 26.0825, 26.0523,  ..., 26.7084, 25.3031, 29.4244],\n",
       "         [23.1251, 18.6502, 21.0266,  ..., 22.5754, 21.2109, 23.3573],\n",
       "         ...,\n",
       "         [25.1036, 22.5513, 22.3583,  ..., 24.0984, 21.4912, 25.7626],\n",
       "         [27.8711, 26.1996, 28.3960,  ..., 28.1598, 26.7288, 29.3992],\n",
       "         [25.7352, 23.6336, 24.4582,  ..., 24.2492, 23.4219, 24.6092]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(tensor2.dot(tensor2)) # gives error, dot product is not possible for 3D tensor\n",
    "tensor2.matmul(tensor2) # matrix multiplication is possible for 3D tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor3 = torch.rand(100,100)\n",
    "# tensor3.dot(tensor3) # dot product is possible for 2D tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[25.5972, 27.0957, 26.6306,  ..., 24.8638, 27.8095, 23.9729],\n",
      "        [25.5634, 29.4885, 26.5628,  ..., 24.2803, 24.8205, 25.0753],\n",
      "        [21.1980, 24.3084, 20.9092,  ..., 21.5096, 22.2073, 20.7957],\n",
      "        ...,\n",
      "        [26.3247, 29.4175, 25.9391,  ..., 23.7574, 26.9102, 25.2673],\n",
      "        [25.3953, 29.8177, 25.8474,  ..., 23.5167, 25.9400, 24.4299],\n",
      "        [24.1506, 26.5884, 24.8052,  ..., 22.0899, 23.3106, 23.7027]])\n"
     ]
    }
   ],
   "source": [
    "# can also use torch.mm(tensor3,tensor3) for matrix multiplication of 2D tensor\n",
    "# torch.mm does not broadcast, matmul does broadcast, meaning matmul can multiply between tensors of different shapes by adjusting the shape of the smaller tensor\n",
    "print(torch.mm(tensor3,tensor3))\n",
    "# print(tensor2.mm(tensor2)) # gives error, mm is not possible for 3D tensor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rules for matrix multiplication\n",
    "- The inner dimensions must match <br>\n",
    "(3,2) @ (2,3) will work because the inner dimensions(2,2) match <br>\n",
    "(3,2) @ (3,2) will not work because the inner dimensions(2,3) do not match\n",
    "\n",
    "(rows,column)\n",
    "\n",
    "- The resulting matrix has the shape of the outer dimensions <br>\n",
    "(3,2) @ (2,3) will result in a (3,3) matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2])\n",
      "torch.Size([2, 3])\n",
      "tensor([[ 10,  22,  34],\n",
      "        [ 22,  50,  78],\n",
      "        [ 34,  78, 122]])\n"
     ]
    }
   ],
   "source": [
    "tensorA = torch.tensor([[1,2],[3,4],[5,6]]) # 3x2\n",
    "tensorB = torch.tensor([[2,4],[6,8],[10,12]]) # 3x2\n",
    "# print(tensorA @ tensorB) # error as inner dimensions are not same\n",
    "# to fix this we can transpose tensorB, i.e. convert 3x2 to 2x3\n",
    "\n",
    "print(tensorB.shape)\n",
    "tensorB = tensorB.T # transpose\n",
    "print(tensorB.shape)\n",
    "print(tensorA @ tensorB) # now it works"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor aggregation\n",
    "- finding mean, sum, max, min, standard deviation, variance, product, argmax, argmin, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
      "tensor(450)\n",
      "tensor(0)\n",
      "tensor(90)\n",
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "tensor_agg = torch.arange(0,100,10)\n",
    "print(tensor_agg)\n",
    "print(tensor_agg.sum()) # sum of all elements\n",
    "print(tensor_agg.prod()) # product of all element\n",
    "print(tensor_agg.max()) # max of all elements\n",
    "print(tensor_agg.min()) # min of all elements\n",
    "# can also use torch.sum(tensor_agg), torch.prod(tensor_agg), torch.max(tensor_agg), torch.min(tensor_agg), etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(45.)\n",
      "tensor(916.6667)\n",
      "tensor(30.2765)\n"
     ]
    }
   ],
   "source": [
    "# print(tensor_agg.dtype) # int64 (long)\n",
    "#mean and std are not possible for int64, so we need to convert it to float\n",
    "tensor_agg = tensor_agg.type(torch.float32)\n",
    "print(tensor_agg.mean()) # mean of all elements, can also use tensor_agg.sum()/len(tensor_agg)\n",
    "print(tensor_agg.var()) # variance of all elements, can also use tensor_agg.std()**2\n",
    "print(tensor_agg.std()) # standard deviation of all elements, can also use tensor_agg.var().sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9)\n",
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "print(tensor_agg.argmax()) # index of max element\n",
    "print(tensor_agg.argmin()) # index of min element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3,  4,  5],\n",
       "        [ 6,  7,  8,  9, 10]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1,2,3,4,5,6,7,8,9,10]).reshape(2,5) # reshape to 2x5, breaks the tensor into 2x5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3,  4,  5],\n",
       "        [ 6,  7,  8,  9, 10]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1,2,3,4,5,6,7,8,9,10]).reshape(2,-1) \n",
    "# reshape to 2x5, breaks the tensor into 2x5, -1 means automatically adjust the number of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c186b54c8cf1ccf367fb8bdf3e071efe85839a5daed090332edb040d14e1fa50"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
