{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(torch.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro to Tensors\n",
    "### Creating tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2)\n",
      "2\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "scalar = torch.tensor(2) # torch.tensor() is used to create a tensor\n",
    "print(scalar) # print the tensor\n",
    "print(scalar.item()) # item() is used to get the value of the tensor\n",
    "print(scalar.ndim) # ndim is used to check the dimension of the tensor, like row or column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5])\n",
      "1\n",
      "torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "vector = torch.tensor([1,2,3,4,5])\n",
    "print(vector)\n",
    "print(vector.ndim) # can say no of square brackets (levels of hierarchy)\n",
    "print(vector.shape) # shape is used to check the shape of the tensor i.e. no of items inside square brackets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "2\n",
      "torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "MATRIX = torch.tensor([[1,2,3],[4,5,6],[7,8,9]])\n",
    "print(MATRIX)\n",
    "print(MATRIX.ndim)\n",
    "print(MATRIX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2, 3],\n",
      "         [4, 5, 6],\n",
      "         [7, 8, 9]],\n",
      "\n",
      "        [[1, 2, 3],\n",
      "         [4, 5, 6],\n",
      "         [7, 8, 9]]])\n",
      "3\n",
      "torch.Size([2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "TENSOR = torch.tensor([[[1,2,3],[4,5,6],[7,8,9]],[[1,2,3],[4,5,6],[7,8,9]]])\n",
    "print(TENSOR)\n",
    "print(TENSOR.ndim)\n",
    "print(TENSOR.shape) # 2,3,3 means 2 matrices of 3 rows and 3 columns (3x3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by convention tensors and matrices are represented by capital letters and scalar and vectors by lower case letters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0680, 0.3903, 0.3812, 0.3191],\n",
       "        [0.2309, 0.3397, 0.5072, 0.9584],\n",
       "        [0.0017, 0.3234, 0.8155, 0.9886]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a random tensor\n",
    "random_tensor = torch.rand(3,4) # 3 rows and 4 columns\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#random image tensor\n",
    "random_image_tensor = torch.rand(3,224,244) # height, width, color channel (RGB)\n",
    "random_image_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#zeros and ones tensor\n",
    "zeros_tensor = torch.zeros(3,4)\n",
    "#zeros_tensor = torch.zeros(size=(3,4)) # same way for size\n",
    "zeros_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones_tensor = torch.ones(3,4)\n",
    "ones_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones_tensor.dtype # data type of the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 4, 6, 8])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_to_ten = torch.arange(0,10)\n",
    "torch.arange(start=0,end=10,step=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensors like\n",
    "# to create a tensor with same shape as other tensor\n",
    "ones_tensor_like = torch.zeros_like(ones_tensor)\n",
    "ones_tensor_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/env_torch/lib/python3.10/site-packages/torch/_tensor_str.py:115: UserWarning: The operator 'aten::nonzero' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:11.)\n",
      "  nonzero_finite_vals = torch.masked_select(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.], device='mps:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#default tensor type is float32\n",
    "\n",
    "float_16_tensor = torch.tensor([1,2,3],\n",
    "                                                dtype=torch.float16, # data type of the tensor\n",
    "                                                device='mps', # what device to use, mps for mac metal gpu, by default cpu\n",
    "                                                requires_grad = False # to calculate gradient or not\n",
    ")\n",
    "float_16_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.], device='mps:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor= float_16_tensor.type(torch.float32)\n",
    "float_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 4., 9.], device='mps:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor * float_16_tensor # possible, results in float32 tensor, this is type casting, float * int = float is also possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float16\n",
      "mps:0\n",
      "False\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "print(float_16_tensor.dtype)\n",
    "print(float_16_tensor.device)\n",
    "print(float_16_tensor.requires_grad)\n",
    "print(float_16_tensor.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations on tensors\n",
    "- Addition\n",
    "- Subtraction\n",
    "- Division\n",
    "- Element wise multiplication\n",
    "- Matrix Multiplication (also known as dot product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "operations = torch.tensor([1,2,3])\n",
    "operations +10 # add 10 to each element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "operations * 10 # multiply 10 to each element (element wise multiplication)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mul(operations,10) # same as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1000, 0.2000, 0.3000])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "operations / 10 # divide 10 to each element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "element wise multiplication: tensor([ 4, 10, 18])\n"
     ]
    }
   ],
   "source": [
    "tensor_mul_1 = torch.tensor([1,2,3])\n",
    "tensor_mul_2 = torch.tensor([4,5,6])\n",
    "print(f\"element wise multiplication: {tensor_mul_1 * tensor_mul_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_mul_1 @ tensor_mul_2 # same as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(tensor_mul_1,tensor_mul_2) # same as above"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## some benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2997, 0.0454, 0.0875,  ..., 0.7646, 0.3664, 0.8544]) torch.Size([100000]) 1\n",
      "tensor(33409.8516)\n",
      "CPU times: user 208 ms, sys: 2.62 ms, total: 210 ms\n",
      "Wall time: 213 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "value =0\n",
    "tensor1 = torch.rand(100000)\n",
    "\n",
    "for i in range(len(tensor1)):\n",
    "    value += tensor1[i] * tensor1[i]\n",
    "\n",
    "print(tensor1,tensor1.shape,tensor1.ndim)\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 413 µs, sys: 1.11 ms, total: 1.53 ms\n",
      "Wall time: 1.46 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(33410.2539)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "torch.matmul(tensor1,tensor1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 117 µs, sys: 126 µs, total: 243 µs\n",
      "Wall time: 478 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(33410.2539)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "tensor1.dot(tensor1) # faster than above\n",
    "# dot and matmul gives same result for 1D tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 100, 100]), 3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor2 = torch.rand(100,100,100)\n",
    "tensor2.shape,tensor2.ndim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[24.1355, 22.5474, 21.2028,  ..., 23.3974, 24.2962, 20.9226],\n",
       "         [26.9782, 23.8141, 23.9537,  ..., 25.0834, 25.1837, 22.7407],\n",
       "         [28.8917, 24.7451, 24.8900,  ..., 27.1475, 25.7138, 26.6879],\n",
       "         ...,\n",
       "         [24.8964, 22.8051, 23.6040,  ..., 24.8836, 24.3157, 22.1827],\n",
       "         [29.4223, 24.2789, 25.2092,  ..., 24.4218, 26.3043, 25.6475],\n",
       "         [26.5048, 22.8048, 23.0850,  ..., 24.8098, 25.7140, 23.7128]],\n",
       "\n",
       "        [[19.5590, 23.4508, 22.2768,  ..., 20.7265, 21.6137, 20.8505],\n",
       "         [22.1140, 26.7733, 24.3902,  ..., 25.1827, 23.5018, 25.3075],\n",
       "         [19.2721, 22.8501, 22.6267,  ..., 22.6890, 21.9649, 21.5033],\n",
       "         ...,\n",
       "         [21.0523, 25.3162, 23.7720,  ..., 25.1456, 24.0636, 21.8882],\n",
       "         [22.1876, 25.5806, 25.2815,  ..., 23.9183, 22.7452, 24.2331],\n",
       "         [21.2688, 24.6019, 23.9528,  ..., 24.6465, 24.0688, 23.8682]],\n",
       "\n",
       "        [[23.6685, 27.7340, 26.4463,  ..., 24.9889, 25.7199, 25.5952],\n",
       "         [26.3906, 29.2407, 28.4798,  ..., 26.7399, 26.8942, 27.4948],\n",
       "         [24.9386, 25.4067, 26.6898,  ..., 25.7567, 25.4414, 26.6388],\n",
       "         ...,\n",
       "         [23.2922, 24.5815, 24.3529,  ..., 25.3917, 23.7298, 25.4068],\n",
       "         [24.1648, 27.0143, 26.9655,  ..., 28.2288, 27.1077, 27.6645],\n",
       "         [26.7362, 29.7778, 28.6133,  ..., 27.4293, 27.6336, 29.2002]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[26.3517, 25.2960, 26.9860,  ..., 25.5747, 23.1937, 21.8445],\n",
       "         [27.2904, 23.9375, 26.5825,  ..., 25.1354, 22.4500, 20.5670],\n",
       "         [29.1616, 28.9457, 29.5970,  ..., 29.4652, 25.4948, 25.3974],\n",
       "         ...,\n",
       "         [25.2977, 22.0098, 25.0652,  ..., 26.6496, 23.5514, 22.4543],\n",
       "         [28.9648, 28.7149, 29.9425,  ..., 28.9018, 24.9107, 25.1759],\n",
       "         [28.9476, 24.8186, 29.2184,  ..., 27.0896, 24.8814, 23.9766]],\n",
       "\n",
       "        [[22.7722, 25.8431, 26.0248,  ..., 27.1881, 23.2627, 24.6047],\n",
       "         [23.1548, 28.4788, 23.8666,  ..., 27.4006, 23.5037, 25.3135],\n",
       "         [24.7128, 28.9905, 26.7748,  ..., 28.0695, 24.5832, 26.0177],\n",
       "         ...,\n",
       "         [21.6568, 25.3597, 23.3547,  ..., 23.9298, 21.5900, 23.9239],\n",
       "         [20.9601, 25.3777, 23.3504,  ..., 25.0942, 20.9986, 23.0584],\n",
       "         [22.3724, 26.2123, 23.8723,  ..., 25.5940, 23.7922, 26.5638]],\n",
       "\n",
       "        [[22.8529, 25.3334, 23.8900,  ..., 23.8247, 24.5259, 23.9072],\n",
       "         [28.8715, 27.6871, 26.7238,  ..., 25.8697, 27.7240, 24.5432],\n",
       "         [22.6736, 23.1739, 23.4523,  ..., 23.3460, 25.6132, 20.7379],\n",
       "         ...,\n",
       "         [27.3058, 25.5097, 26.1296,  ..., 25.0357, 26.9089, 23.7602],\n",
       "         [23.6313, 21.3367, 24.4037,  ..., 22.5574, 26.6542, 22.7562],\n",
       "         [24.8775, 21.8773, 23.0781,  ..., 23.0684, 23.8203, 21.4707]]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(tensor2.dot(tensor2)) # gives error, dot product is not possible for 3D tensor\n",
    "tensor2.matmul(tensor2) # matrix multiplication is possible for 3D tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor3 = torch.rand(100,100)\n",
    "# tensor3.dot(tensor3) # dot product is possible for 2D tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[24.8122, 24.6808, 21.5404,  ..., 22.1012, 22.3122, 21.6048],\n",
      "        [25.3132, 26.5542, 25.2134,  ..., 24.4651, 23.7103, 23.5687],\n",
      "        [26.1217, 25.9671, 24.7538,  ..., 24.7833, 23.6987, 23.0907],\n",
      "        ...,\n",
      "        [24.8978, 25.9454, 22.7677,  ..., 23.7624, 23.6002, 22.1892],\n",
      "        [24.4345, 26.3747, 24.4636,  ..., 22.0047, 25.3130, 23.9794],\n",
      "        [25.0486, 26.3797, 22.5511,  ..., 23.8049, 25.0386, 23.5396]])\n"
     ]
    }
   ],
   "source": [
    "# can also use torch.mm(tensor3,tensor3) for matrix multiplication of 2D tensor\n",
    "# torch.mm does not broadcast, matmul does broadcast, meaning matmul can multiply between tensors of different shapes by adjusting the shape of the smaller tensor\n",
    "print(torch.mm(tensor3,tensor3))\n",
    "# print(tensor2.mm(tensor2)) # gives error, mm is not possible for 3D tensor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rules for matrix multiplication\n",
    "- The inner dimensions must match <br>\n",
    "(3,2) @ (2,3) will work because the inner dimensions(2,2) match <br>\n",
    "(3,2) @ (3,2) will not work because the inner dimensions(2,3) do not match\n",
    "\n",
    "(rows,column)\n",
    "\n",
    "- The resulting matrix has the shape of the outer dimensions <br>\n",
    "(3,2) @ (2,3) will result in a (3,3) matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2])\n",
      "torch.Size([2, 3])\n",
      "tensor([[ 10,  22,  34],\n",
      "        [ 22,  50,  78],\n",
      "        [ 34,  78, 122]])\n"
     ]
    }
   ],
   "source": [
    "tensorA = torch.tensor([[1,2],[3,4],[5,6]]) # 3x2\n",
    "tensorB = torch.tensor([[2,4],[6,8],[10,12]]) # 3x2\n",
    "# print(tensorA @ tensorB) # error as inner dimensions are not same\n",
    "# to fix this we can transpose tensorB, i.e. convert 3x2 to 2x3\n",
    "\n",
    "print(tensorB.shape)\n",
    "tensorB = tensorB.T # transpose\n",
    "print(tensorB.shape)\n",
    "print(tensorA @ tensorB) # now it works"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor aggregation\n",
    "- finding mean, sum, max, min, standard deviation, variance, product, argmax, argmin, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
      "tensor(450)\n",
      "tensor(0)\n",
      "tensor(90)\n",
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "tensor_agg = torch.arange(0,100,10)\n",
    "print(tensor_agg)\n",
    "print(tensor_agg.sum()) # sum of all elements\n",
    "print(tensor_agg.prod()) # product of all element\n",
    "print(tensor_agg.max()) # max of all elements\n",
    "print(tensor_agg.min()) # min of all elements\n",
    "# can also use torch.sum(tensor_agg), torch.prod(tensor_agg), torch.max(tensor_agg), torch.min(tensor_agg), etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(45.)\n",
      "tensor(916.6667)\n",
      "tensor(30.2765)\n"
     ]
    }
   ],
   "source": [
    "# print(tensor_agg.dtype) # int64 (long)\n",
    "#mean and std are not possible for int64, so we need to convert it to float\n",
    "tensor_agg = tensor_agg.type(torch.float32)\n",
    "print(tensor_agg.mean()) # mean of all elements, can also use tensor_agg.sum()/len(tensor_agg)\n",
    "print(tensor_agg.var()) # variance of all elements, can also use tensor_agg.std()**2\n",
    "print(tensor_agg.std()) # standard deviation of all elements, can also use tensor_agg.var().sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9)\n",
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "print(tensor_agg.argmax()) # index of max element\n",
    "print(tensor_agg.argmin()) # index of min element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3,  4,  5],\n",
       "        [ 6,  7,  8,  9, 10]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1,2,3,4,5,6,7,8,9,10]).reshape(2,5) # reshape to 2x5, breaks the tensor into 2x5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3,  4,  5],\n",
       "        [ 6,  7,  8,  9, 10]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1,2,3,4,5,6,7,8,9,10]).reshape(2,-1) \n",
    "# reshape to 2x5, breaks the tensor into 2x5, -1 means automatically adjust the number of columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping, stacking, squeezing, unsqueezing, permute of tensors\n",
    "\n",
    "Why do any of these?\n",
    "\n",
    "Because deep learning models (neural networks) are all about manipulating tensors in some way. And because of the rules of matrix multiplication, if you've got shape mismatches, you'll run into errors. These methods help you make the right elements of your tensors are mixing with the right elements of other tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7.]), torch.Size([7]), 1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.arange(1.,8.)\n",
    "x , x.shape, x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]), 2)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reshape\n",
    "x_reshaped = x.reshape(1,7) # it has to be compatible with the original shape (1x7) or (7x1) or (7,) or (1,7,1) or (1,1,7)\n",
    "# (2,7) is not possible as it is not compatible with the original shape, i.e. 2x7 = 14 != 7 (original shape)\n",
    "x_reshaped , x_reshaped.shape , x_reshaped.ndim #one dimension is added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.,  2.,  3.,  4.,  5.],\n",
       "         [ 6.,  7.,  8.,  9., 10.]]),\n",
       " torch.Size([2, 5]),\n",
       " 2)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.arange(1.,11.) \n",
    "y , y.shape\n",
    "\n",
    "y_reshaped = y.reshape(2,5) # compatible as 2x5 = 10 = 10 (original shape)\n",
    "y_reshaped , y_reshaped.shape , y_reshaped.ndim #one dimension is added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]), 2)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view is same as reshape, but it does not create a copy of the tensor, it just changes the view of the tensor, sharing same memory\n",
    "x_view = x.view(1,7)\n",
    "x_view , x_view.shape , x_view.ndim\n",
    "# if we change x_view, x will also change as they share same memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3., 4., 5., 6., 7.],\n",
      "        [1., 2., 3., 4., 5., 6., 7.],\n",
      "        [1., 2., 3., 4., 5., 6., 7.],\n",
      "        [1., 2., 3., 4., 5., 6., 7.]])\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [2., 2., 2., 2.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [4., 4., 4., 4.],\n",
      "        [5., 5., 5., 5.],\n",
      "        [6., 6., 6., 6.],\n",
      "        [7., 7., 7., 7.]])\n"
     ]
    }
   ],
   "source": [
    "# Stack tensors on top of each other\n",
    "x_stacked = torch.stack([x, x, x, x], dim=0) \n",
    "print(x_stacked)\n",
    "x_stacked2 = torch.stack([x, x, x, x], dim=1)\n",
    "print(x_stacked2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous tensor: tensor([[1., 2., 3., 4., 5., 6., 7.]])\n",
      "Previous shape: torch.Size([1, 7])\n",
      "\n",
      "New tensor: tensor([1., 2., 3., 4., 5., 6., 7.])\n",
      "New shape: torch.Size([7])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7.]), torch.Size([7]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Previous tensor: {x_reshaped}\")\n",
    "print(f\"Previous shape: {x_reshaped.shape}\")\n",
    "\n",
    "# Remove extra dimension from x_reshaped, squeeze() removes all the dimensions with value 1, upto 1D tensor\n",
    "x_squeezed = x_reshaped.squeeze()\n",
    "print(f\"\\nNew tensor: {x_squeezed}\")\n",
    "print(f\"New shape: {x_squeezed.shape}\")\n",
    "x.squeeze(), x.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous tensor: tensor([1., 2., 3., 4., 5., 6., 7.])\n",
      "Previous shape: torch.Size([7])\n",
      "\n",
      "New tensor: tensor([[1., 2., 3., 4., 5., 6., 7.]])\n",
      "New shape: torch.Size([1, 7])\n"
     ]
    }
   ],
   "source": [
    "# unsqueeze() adds a dimension with value 1, upto 3D tensor, its opposite of squeeze()\n",
    "print(f\"Previous tensor: {x_squeezed}\")\n",
    "print(f\"Previous shape: {x_squeezed.shape}\")\n",
    "\n",
    "## Add an extra dimension with unsqueeze\n",
    "x_unsqueezed = x_squeezed.unsqueeze(dim=0)\n",
    "print(f\"\\nNew tensor: {x_unsqueezed}\")\n",
    "print(f\"New shape: {x_unsqueezed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous shape: torch.Size([224, 224, 3])\n",
      "New shape: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# permute rearrange the order of axes values with torch.permute(input, dims), where the input gets turned into a view with new dims.\n",
    "# Create tensor with specific shape\n",
    "x_original = torch.rand(size=(224, 224, 3)) # [Height, Width, Channels], common representation of an image data\n",
    "\n",
    "# Permute the original tensor to rearrange the axis order\n",
    "x_permuted = x_original.permute(2, 0, 1) # shifts axis 0->1, 1->2, 2->0\n",
    "\n",
    "print(f\"Previous shape: {x_original.shape}\")\n",
    "print(f\"New shape: {x_permuted.shape}\") # [Channels, Height, Width]\n",
    "# it is just a memory view, so if we change x_permuted, x_original will also change"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexing (Selecting data from tensors) in PyTorch\n",
    "(for example, only the first column or second row)\n",
    "(similar to numpy indexing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [4, 5, 6],\n",
       "          [7, 8, 9]]]),\n",
       " torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.arange(1,10).reshape(1,3,3) # 1 matrix of 3x3\n",
    "x , x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First square bracket:\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "Second square bracket: tensor([1, 2, 3])\n",
      "Third square bracket: 1\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(4)\n",
      "tensor(5)\n"
     ]
    }
   ],
   "source": [
    "print(f\"First square bracket:\\n{x[0]}\") \n",
    "print(f\"Second square bracket: {x[0][0]}\") \n",
    "print(f\"Third square bracket: {x[0][0][0]}\")\n",
    "# or we can use x[0,0,0]\n",
    "print(x[0,0,1])\n",
    "print(x[0,0,2])\n",
    "print(x[0,1,0])\n",
    "print(x[0,1,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3]])\n",
      "tensor([[2, 5, 8]])\n",
      "tensor([5])\n",
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Get all values of 0th dimension and the 0 index of 1st dimension\n",
    "print(x[:, 0])\n",
    "# Get all values of 0th & 1st dimensions but only index 1 of 2nd dimension\n",
    "print(x[:, :, 1])\n",
    "# Get all values of the 0 dimension but only the 1 index value of the 1st and 2nd dimension\n",
    "print(x[:, 1, 1])\n",
    "# Get index 0 of 0th and 1st dimension and all values of 2nd dimension \n",
    "print(x[0, 0, :]) # same as x[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 3],\n",
       "        [5, 6]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,:2,1:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch tensors & NumPy\n",
    "- torch.from_numpy(ndarray) - NumPy array -> PyTorch tensor.\n",
    "- torch.Tensor.numpy() - PyTorch tensor -> NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NumPy array to tensor\n",
    "import torch\n",
    "import numpy as np\n",
    "array = np.arange(1.0, 8.0)\n",
    "tensor = torch.from_numpy(array) # from_numpy() is used to convert numpy array to tensor\n",
    "# default dtype is float64 of numpy and float32 of tensor in pytorch\n",
    "tensor2 = torch.tensor(array).type(torch.float32)  \n",
    "\n",
    "array, tensor , tensor2.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 3., 4., 5., 6., 7., 8.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# changing the array after converting to tensor will not change the tensor as they dont share same memory\n",
    "array = array + 1\n",
    "\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor to NumPy array\n",
    "tensor = torch.ones(7) # create a tensor of ones with dtype=float32\n",
    "numpy_tensor = tensor.numpy() # will be dtype=float32 unless changed\n",
    "tensor, numpy_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2., 2., 2., 2., 2., 2., 2.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the tensor, keep the array the same\n",
    "tensor = tensor + 1\n",
    "tensor, numpy_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c186b54c8cf1ccf367fb8bdf3e071efe85839a5daed090332edb040d14e1fa50"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
